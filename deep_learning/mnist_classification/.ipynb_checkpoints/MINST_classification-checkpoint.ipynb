{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff743b7-637d-4edb-abdc-0372ae074934",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78c6b9d-38fc-4682-bbe6-3609ce870c59",
   "metadata": {},
   "source": [
    "### Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c4b2dd4-180d-44e9-8698-07ee1076a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2aa330f3-ecbe-4d0a-93d2-caf4b410815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "506227bc-a93d-4ef6-ad4a-cab66c6ed791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 12:03:24.825109: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "# make 10% of train data a validation data\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "# scale all the values for numerical stability\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "    return image, label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "scaled_test_data = mnist_test.map(scale)\n",
    "\n",
    "# shuffle data\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "# exatrct validation data\n",
    "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
    "# shuffle remaining train data\n",
    "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = scaled_test_data.batch(num_test_samples)\n",
    "\n",
    "# divide validation data into 2 \n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb57c7ba-6752-449e-9a49-d662e6714963",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c25e8-9c4b-4bac-97f3-02cd63293e93",
   "metadata": {},
   "source": [
    "### Ouline the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27cbafd6-5841-400d-bae7-57572cc68bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 200\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.Input(shape=(28, 28, 1)),  # ✅ define input shape here\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation = 'relu'),\n",
    "                            tf.keras.layers.Dense(output_size, activation = 'softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26db7c3-cac4-4ef0-a334-fe283312cb16",
   "metadata": {},
   "source": [
    "### Choose the Optimizer and the Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bea2d43e-2b85-4d52-ad91-72a6e1953b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "# sparse_categorical_crossentropy as targets are in for of integers\n",
    "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f22a66-763f-432b-920c-d219d04d09cc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a01b2a9-ce4d-4ba8-beaf-caf8fa7d1742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "540/540 - 2s - 3ms/step - accuracy: 0.9028 - loss: 0.3556 - val_accuracy: 0.9477 - val_loss: 0.1760\n",
      "Epoch 2/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9595 - loss: 0.1372 - val_accuracy: 0.9660 - val_loss: 0.1192\n",
      "Epoch 3/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9724 - loss: 0.0949 - val_accuracy: 0.9742 - val_loss: 0.0896\n",
      "Epoch 4/50\n",
      "540/540 - 1s - 2ms/step - accuracy: 0.9788 - loss: 0.0717 - val_accuracy: 0.9760 - val_loss: 0.0784\n",
      "Epoch 5/50\n",
      "540/540 - 1s - 2ms/step - accuracy: 0.9830 - loss: 0.0563 - val_accuracy: 0.9835 - val_loss: 0.0579\n",
      "Epoch 6/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9869 - loss: 0.0439 - val_accuracy: 0.9838 - val_loss: 0.0555\n",
      "Epoch 7/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9894 - loss: 0.0361 - val_accuracy: 0.9858 - val_loss: 0.0422\n",
      "Epoch 8/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9915 - loss: 0.0287 - val_accuracy: 0.9887 - val_loss: 0.0346\n",
      "Epoch 9/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9923 - loss: 0.0244 - val_accuracy: 0.9907 - val_loss: 0.0274\n",
      "Epoch 10/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9944 - loss: 0.0199 - val_accuracy: 0.9905 - val_loss: 0.0303\n",
      "Epoch 11/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9961 - loss: 0.0147 - val_accuracy: 0.9942 - val_loss: 0.0204\n",
      "Epoch 12/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9966 - loss: 0.0132 - val_accuracy: 0.9932 - val_loss: 0.0192\n",
      "Epoch 13/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9966 - loss: 0.0118 - val_accuracy: 0.9960 - val_loss: 0.0122\n",
      "Epoch 14/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 0.9960 - val_loss: 0.0120\n",
      "Epoch 15/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9978 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9978 - loss: 0.0077 - val_accuracy: 0.9948 - val_loss: 0.0149\n",
      "Epoch 17/50\n",
      "540/540 - 1s - 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9960 - val_loss: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35a1842f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_data, epochs = NUM_EPOCHS, validation_data = (validation_inputs,validation_targets), verbose = 2, callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2454f0-0158-4743-b547-8d815e90f49a",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9851a044-fc4f-4c3a-9866-38d4f5b25305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9763 - loss: 0.0742\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ab478-db9f-4aa7-aa7b-7f2a122ec2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
